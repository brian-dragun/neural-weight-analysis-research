name: "gpt2"
model_size: "small"
device: "cuda"  # Lambda Labs default
torch_dtype: "float16"  # GPU optimized
max_length: 512
quantization: null
device_map: "auto"
low_cpu_mem_usage: true
cache_dir: "/tmp/hf_cache"
use_flash_attention_2: true