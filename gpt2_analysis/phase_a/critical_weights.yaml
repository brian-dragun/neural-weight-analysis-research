attack_surface:
  attack_vectors:
  - severity: medium
    target: h.11.mlp.c_fc.weight
    type: computation_disruption
    weight_count: 5
  - severity: medium
    target: h.11.mlp.c_proj.bias
    type: computation_disruption
    weight_count: 5
  - severity: medium
    target: h.6.mlp.c_fc.bias
    type: computation_disruption
    weight_count: 2
  - severity: medium
    target: h.10.mlp.c_fc.bias
    type: computation_disruption
    weight_count: 3
  - severity: medium
    target: h.5.mlp.c_fc.bias
    type: computation_disruption
    weight_count: 2
  - severity: medium
    target: h.8.mlp.c_fc.bias
    type: computation_disruption
    weight_count: 2
  - severity: high
    target: h.11.attn.c_attn.bias
    type: attention_disruption
    weight_count: 16
  - severity: medium
    target: h.11.mlp.c_proj.weight
    type: computation_disruption
    weight_count: 3
  - severity: high
    target: h.10.attn.c_attn.weight
    type: attention_disruption
    weight_count: 8
  - severity: high
    target: h.11.attn.c_proj.bias
    type: attention_disruption
    weight_count: 6
  - severity: high
    target: h.10.attn.c_attn.bias
    type: attention_disruption
    weight_count: 6
  - severity: medium
    target: h.3.mlp.c_fc.weight
    type: computation_disruption
    weight_count: 1
  - severity: high
    target: h.11.attn.c_attn.weight
    type: attention_disruption
    weight_count: 12
  - severity: medium
    target: h.7.mlp.c_fc.bias
    type: computation_disruption
    weight_count: 2
  - severity: medium
    target: h.9.mlp.c_fc.bias
    type: computation_disruption
    weight_count: 3
  - severity: high
    target: h.11.attn.c_proj.weight
    type: attention_disruption
    weight_count: 18
  - severity: high
    target: h.10.attn.c_proj.bias
    type: attention_disruption
    weight_count: 2
  - severity: medium
    target: h.11.mlp.c_fc.bias
    type: computation_disruption
    weight_count: 2
  - severity: medium
    target: h.10.mlp.c_proj.bias
    type: computation_disruption
    weight_count: 1
  - severity: high
    target: h.9.attn.c_proj.bias
    type: attention_disruption
    weight_count: 1
  - severity: high
    target: h.10.attn.c_proj.weight
    type: attention_disruption
    weight_count: 3
  - severity: medium
    target: h.10.mlp.c_fc.weight
    type: computation_disruption
    weight_count: 3
  - severity: high
    target: h.9.attn.c_attn.bias
    type: attention_disruption
    weight_count: 2
  - severity: high
    target: h.2.attn.c_attn.bias
    type: attention_disruption
    weight_count: 1
  - severity: medium
    target: h.8.mlp.c_proj.bias
    type: computation_disruption
    weight_count: 1
  - severity: medium
    target: h.9.mlp.c_proj.bias
    type: computation_disruption
    weight_count: 1
  - severity: medium
    target: h.7.mlp.c_proj.bias
    type: computation_disruption
    weight_count: 1
  - severity: high
    target: h.9.attn.c_attn.weight
    type: attention_disruption
    weight_count: 1
  - severity: high
    target: h.9.attn.c_proj.weight
    type: attention_disruption
    weight_count: 1
  - severity: medium
    target: h.4.mlp.c_fc.bias
    type: computation_disruption
    weight_count: 1
  - severity: high
    target: h.8.attn.c_proj.bias
    type: attention_disruption
    weight_count: 1
  - severity: high
    target: h.6.attn.c_attn.weight
    type: attention_disruption
    weight_count: 2
  - severity: medium
    target: h.6.mlp.c_proj.bias
    type: computation_disruption
    weight_count: 1
  - severity: high
    target: h.7.attn.c_attn.weight
    type: attention_disruption
    weight_count: 1
  - severity: high
    target: h.8.attn.c_attn.weight
    type: attention_disruption
    weight_count: 2
  - severity: high
    target: h.8.attn.c_proj.weight
    type: attention_disruption
    weight_count: 1
  - severity: medium
    target: h.9.mlp.c_fc.weight
    type: computation_disruption
    weight_count: 1
  - severity: high
    target: h.6.attn.c_proj.bias
    type: attention_disruption
    weight_count: 2
  - severity: high
    target: h.8.attn.c_attn.bias
    type: attention_disruption
    weight_count: 2
  - severity: medium
    target: h.10.mlp.c_proj.weight
    type: computation_disruption
    weight_count: 1
  risk_assessment:
    attack_vector_count: 40
    most_vulnerable_layer: h.11.attn.c_proj.weight
    overall_risk: high
  total_critical_weights: 141
  vulnerable_layers: !!set
    h.10.attn.c_attn.bias: null
    h.10.attn.c_attn.weight: null
    h.10.attn.c_proj.bias: null
    h.10.attn.c_proj.weight: null
    h.10.ln_2.bias: null
    h.10.mlp.c_fc.bias: null
    h.10.mlp.c_fc.weight: null
    h.10.mlp.c_proj.bias: null
    h.10.mlp.c_proj.weight: null
    h.11.attn.c_attn.bias: null
    h.11.attn.c_attn.weight: null
    h.11.attn.c_proj.bias: null
    h.11.attn.c_proj.weight: null
    h.11.ln_2.bias: null
    h.11.mlp.c_fc.bias: null
    h.11.mlp.c_fc.weight: null
    h.11.mlp.c_proj.bias: null
    h.11.mlp.c_proj.weight: null
    h.2.attn.c_attn.bias: null
    h.2.ln_2.weight: null
    h.3.ln_2.bias: null
    h.3.mlp.c_fc.weight: null
    h.4.ln_2.bias: null
    h.4.mlp.c_fc.bias: null
    h.5.mlp.c_fc.bias: null
    h.6.attn.c_attn.weight: null
    h.6.attn.c_proj.bias: null
    h.6.mlp.c_fc.bias: null
    h.6.mlp.c_proj.bias: null
    h.7.attn.c_attn.weight: null
    h.7.mlp.c_fc.bias: null
    h.7.mlp.c_proj.bias: null
    h.8.attn.c_attn.bias: null
    h.8.attn.c_attn.weight: null
    h.8.attn.c_proj.bias: null
    h.8.attn.c_proj.weight: null
    h.8.mlp.c_fc.bias: null
    h.8.mlp.c_proj.bias: null
    h.9.attn.c_attn.bias: null
    h.9.attn.c_attn.weight: null
    h.9.attn.c_proj.bias: null
    h.9.attn.c_proj.weight: null
    h.9.mlp.c_fc.bias: null
    h.9.mlp.c_fc.weight: null
    h.9.mlp.c_proj.bias: null
    ln_f.weight: null
critical_weights:
- !!python/tuple
  - h.11.mlp.c_fc.weight
  - 965219
  - 1.16015625
- !!python/tuple
  - h.11.mlp.c_proj.bias
  - 496
  - 1.09375
- !!python/tuple
  - h.11.mlp.c_proj.bias
  - 430
  - 1.0830078125
- !!python/tuple
  - h.6.mlp.c_fc.bias
  - 437
  - 1.0703125
- !!python/tuple
  - h.10.ln_2.bias
  - 373
  - 1.0498046875
- !!python/tuple
  - h.10.mlp.c_fc.bias
  - 379
  - 1.0361328125
- !!python/tuple
  - h.5.mlp.c_fc.bias
  - 1888
  - 1.01953125
- !!python/tuple
  - h.8.mlp.c_fc.bias
  - 1253
  - 0.98876953125
- !!python/tuple
  - h.11.attn.c_attn.bias
  - 302
  - 0.98828125
- !!python/tuple
  - h.11.mlp.c_proj.weight
  - 469562
  - 0.95849609375
- !!python/tuple
  - h.10.ln_2.bias
  - 481
  - 0.94580078125
- !!python/tuple
  - h.8.mlp.c_fc.bias
  - 1640
  - 0.94189453125
- !!python/tuple
  - h.5.mlp.c_fc.bias
  - 1505
  - 0.94091796875
- !!python/tuple
  - h.11.ln_2.bias
  - 373
  - 0.9189453125
- !!python/tuple
  - h.10.attn.c_attn.weight
  - 613211
  - 0.91357421875
- !!python/tuple
  - h.11.attn.c_proj.bias
  - 393
  - 0.90185546875
- !!python/tuple
  - h.11.attn.c_attn.bias
  - 2059
  - 0.90087890625
- !!python/tuple
  - h.10.mlp.c_fc.bias
  - 900
  - 0.89990234375
- !!python/tuple
  - h.4.ln_2.bias
  - 138
  - 0.89892578125
- !!python/tuple
  - h.4.ln_2.bias
  - 480
  - 0.89794921875
- !!python/tuple
  - h.10.attn.c_attn.bias
  - 347
  - 0.89697265625
- !!python/tuple
  - h.11.attn.c_attn.bias
  - 2290
  - 0.89306640625
- !!python/tuple
  - h.11.attn.c_attn.bias
  - 2061
  - 0.890625
- !!python/tuple
  - h.3.mlp.c_fc.weight
  - 424963
  - 0.88671875
- !!python/tuple
  - h.11.attn.c_proj.bias
  - 314
  - 0.88671875
- !!python/tuple
  - h.11.mlp.c_proj.bias
  - 314
  - 0.8857421875
- !!python/tuple
  - h.11.attn.c_attn.weight
  - 320242
  - 0.88427734375
- !!python/tuple
  - h.7.mlp.c_fc.bias
  - 2367
  - 0.88330078125
- !!python/tuple
  - ln_f.weight
  - 496
  - 0.88330078125
- !!python/tuple
  - h.9.mlp.c_fc.bias
  - 1503
  - 0.8828125
- !!python/tuple
  - h.11.attn.c_proj.weight
  - 403647
  - 0.88134765625
- !!python/tuple
  - h.10.attn.c_proj.bias
  - 138
  - 0.880859375
- !!python/tuple
  - h.11.attn.c_attn.bias
  - 2078
  - 0.87646484375
- !!python/tuple
  - h.11.mlp.c_fc.weight
  - 1002083
  - 0.875
- !!python/tuple
  - h.11.mlp.c_fc.bias
  - 611
  - 0.875
- !!python/tuple
  - h.11.attn.c_proj.weight
  - 402057
  - 0.8740234375
- !!python/tuple
  - h.3.ln_2.bias
  - 138
  - 0.873046875
- !!python/tuple
  - h.10.mlp.c_proj.bias
  - 138
  - 0.8662109375
- !!python/tuple
  - h.11.mlp.c_fc.weight
  - 1926755
  - 0.865234375
- !!python/tuple
  - h.11.attn.c_attn.bias
  - 277
  - 0.86181640625
- !!python/tuple
  - h.9.attn.c_proj.bias
  - 138
  - 0.861328125
- !!python/tuple
  - h.10.attn.c_attn.bias
  - 1862
  - 0.861328125
- !!python/tuple
  - h.9.mlp.c_fc.bias
  - 1889
  - 0.85888671875
- !!python/tuple
  - h.11.attn.c_proj.weight
  - 397449
  - 0.85888671875
- !!python/tuple
  - h.10.attn.c_proj.weight
  - 78474
  - 0.8583984375
- !!python/tuple
  - h.10.attn.c_attn.weight
  - 1031750
  - 0.85693359375
- !!python/tuple
  - h.11.attn.c_attn.bias
  - 2053
  - 0.85693359375
- !!python/tuple
  - h.11.ln_2.bias
  - 447
  - 0.8564453125
- !!python/tuple
  - h.11.attn.c_attn.weight
  - 320013
  - 0.85595703125
- !!python/tuple
  - h.11.mlp.c_proj.bias
  - 374
  - 0.8544921875
metadata:
  analysis_method: security_gradient_combined
  threshold: 0.8
  total_weights_analyzed: 237137
model: gpt2
phase: A
vulnerability_map:
  h.0.attn.c_attn.bias: 0.449951171875
  h.0.attn.c_attn.weight: 0.28662109375
  h.0.attn.c_proj.bias: 0.4287109375
  h.0.attn.c_proj.weight: 0.2783203125
  h.0.ln_1.bias: 0.37646484375
  h.0.ln_1.weight: 0.483642578125
  h.0.ln_2.bias: 0.373779296875
  h.0.ln_2.weight: 0.463134765625
  h.0.mlp.c_fc.bias: 0.389404296875
  h.0.mlp.c_fc.weight: 0.2275390625
  h.0.mlp.c_proj.bias: 0.42236328125
  h.0.mlp.c_proj.weight: 0.2169189453125
  h.1.attn.c_attn.bias: 0.436279296875
  h.1.attn.c_attn.weight: 0.34228515625
  h.1.attn.c_proj.bias: 0.499267578125
  h.1.attn.c_proj.weight: 0.285888671875
  h.1.ln_1.bias: 0.386474609375
  h.1.ln_1.weight: 0.34130859375
  h.1.ln_2.bias: 0.382080078125
  h.1.ln_2.weight: 0.395751953125
  h.1.mlp.c_fc.bias: 0.385009765625
  h.1.mlp.c_fc.weight: 0.265625
  h.1.mlp.c_proj.bias: 0.442626953125
  h.1.mlp.c_proj.weight: 0.2296142578125
  h.10.attn.c_attn.bias: 0.64599609375
  h.10.attn.c_attn.weight: 0.50048828125
  h.10.attn.c_proj.bias: 0.52783203125
  h.10.attn.c_proj.weight: 0.47802734375
  h.10.ln_1.bias: 0.56396484375
  h.10.ln_1.weight: 0.47412109375
  h.10.ln_2.bias: 0.4189453125
  h.10.ln_2.weight: 0.42529296875
  h.10.mlp.c_fc.bias: 0.49560546875
  h.10.mlp.c_fc.weight: 0.4384765625
  h.10.mlp.c_proj.bias: 0.5361328125
  h.10.mlp.c_proj.weight: 0.41259765625
  h.11.attn.c_attn.bias: 0.6796875
  h.11.attn.c_attn.weight: 0.51513671875
  h.11.attn.c_proj.bias: 0.625
  h.11.attn.c_proj.weight: 0.497314453125
  h.11.ln_1.bias: 0.399658203125
  h.11.ln_1.weight: 0.52783203125
  h.11.ln_2.bias: 0.5791015625
  h.11.ln_2.weight: 0.5146484375
  h.11.mlp.c_fc.bias: 0.51513671875
  h.11.mlp.c_fc.weight: 0.470947265625
  h.11.mlp.c_proj.bias: 0.6416015625
  h.11.mlp.c_proj.weight: 0.437255859375
  h.2.attn.c_attn.bias: 0.46435546875
  h.2.attn.c_attn.weight: 0.3447265625
  h.2.attn.c_proj.bias: 0.60791015625
  h.2.attn.c_proj.weight: 0.319580078125
  h.2.ln_1.bias: 0.408203125
  h.2.ln_1.weight: 0.324462890625
  h.2.ln_2.bias: 0.351806640625
  h.2.ln_2.weight: 0.35302734375
  h.2.mlp.c_fc.bias: 0.31396484375
  h.2.mlp.c_fc.weight: 0.25048828125
  h.2.mlp.c_proj.bias: 0.45556640625
  h.2.mlp.c_proj.weight: 0.2459716796875
  h.3.attn.c_attn.bias: 0.5224609375
  h.3.attn.c_attn.weight: 0.35107421875
  h.3.attn.c_proj.bias: 0.51708984375
  h.3.attn.c_proj.weight: 0.33544921875
  h.3.ln_1.bias: 0.4453125
  h.3.ln_1.weight: 0.3671875
  h.3.ln_2.bias: 0.486328125
  h.3.ln_2.weight: 0.31201171875
  h.3.mlp.c_fc.bias: 0.413330078125
  h.3.mlp.c_fc.weight: 0.298583984375
  h.3.mlp.c_proj.bias: 0.452392578125
  h.3.mlp.c_proj.weight: 0.271240234375
  h.4.attn.c_attn.bias: 0.48828125
  h.4.attn.c_attn.weight: 0.3505859375
  h.4.attn.c_proj.bias: 0.54296875
  h.4.attn.c_proj.weight: 0.366943359375
  h.4.ln_1.bias: 0.445068359375
  h.4.ln_1.weight: 0.406982421875
  h.4.ln_2.bias: 0.53271484375
  h.4.ln_2.weight: 0.310302734375
  h.4.mlp.c_fc.bias: 0.42236328125
  h.4.mlp.c_fc.weight: 0.326904296875
  h.4.mlp.c_proj.bias: 0.42333984375
  h.4.mlp.c_proj.weight: 0.296875
  h.5.attn.c_attn.bias: 0.54296875
  h.5.attn.c_attn.weight: 0.408203125
  h.5.attn.c_proj.bias: 0.5146484375
  h.5.attn.c_proj.weight: 0.37646484375
  h.5.ln_1.bias: 0.493896484375
  h.5.ln_1.weight: 0.410888671875
  h.5.ln_2.bias: 0.513671875
  h.5.ln_2.weight: 0.3095703125
  h.5.mlp.c_fc.bias: 0.50146484375
  h.5.mlp.c_fc.weight: 0.3505859375
  h.5.mlp.c_proj.bias: 0.453857421875
  h.5.mlp.c_proj.weight: 0.327880859375
  h.6.attn.c_attn.bias: 0.57080078125
  h.6.attn.c_attn.weight: 0.41943359375
  h.6.attn.c_proj.bias: 0.61474609375
  h.6.attn.c_proj.weight: 0.4091796875
  h.6.ln_1.bias: 0.47802734375
  h.6.ln_1.weight: 0.4130859375
  h.6.ln_2.bias: 0.46728515625
  h.6.ln_2.weight: 0.340576171875
  h.6.mlp.c_fc.bias: 0.493896484375
  h.6.mlp.c_fc.weight: 0.36572265625
  h.6.mlp.c_proj.bias: 0.4560546875
  h.6.mlp.c_proj.weight: 0.35107421875
  h.7.attn.c_attn.bias: 0.6181640625
  h.7.attn.c_attn.weight: 0.43701171875
  h.7.attn.c_proj.bias: 0.62548828125
  h.7.attn.c_proj.weight: 0.424560546875
  h.7.ln_1.bias: 0.51416015625
  h.7.ln_1.weight: 0.427001953125
  h.7.ln_2.bias: 0.480224609375
  h.7.ln_2.weight: 0.35986328125
  h.7.mlp.c_fc.bias: 0.4794921875
  h.7.mlp.c_fc.weight: 0.418212890625
  h.7.mlp.c_proj.bias: 0.4599609375
  h.7.mlp.c_proj.weight: 0.360595703125
  h.8.attn.c_attn.bias: 0.599609375
  h.8.attn.c_attn.weight: 0.454345703125
  h.8.attn.c_proj.bias: 0.52978515625
  h.8.attn.c_proj.weight: 0.438720703125
  h.8.ln_1.bias: 0.52001953125
  h.8.ln_1.weight: 0.414794921875
  h.8.ln_2.bias: 0.410400390625
  h.8.ln_2.weight: 0.389892578125
  h.8.mlp.c_fc.bias: 0.48779296875
  h.8.mlp.c_fc.weight: 0.426513671875
  h.8.mlp.c_proj.bias: 0.474853515625
  h.8.mlp.c_proj.weight: 0.37939453125
  h.9.attn.c_attn.bias: 0.59375
  h.9.attn.c_attn.weight: 0.47509765625
  h.9.attn.c_proj.bias: 0.5439453125
  h.9.attn.c_proj.weight: 0.482421875
  h.9.ln_1.bias: 0.5498046875
  h.9.ln_1.weight: 0.44482421875
  h.9.ln_2.bias: 0.42626953125
  h.9.ln_2.weight: 0.416015625
  h.9.mlp.c_fc.bias: 0.552734375
  h.9.mlp.c_fc.weight: 0.416259765625
  h.9.mlp.c_proj.bias: 0.490234375
  h.9.mlp.c_proj.weight: 0.40185546875
  ln_f.bias: 0.18115234375
  ln_f.weight: 0.266845703125
  wpe.weight: 0.2666015625
  wte.weight: 0.298095703125
