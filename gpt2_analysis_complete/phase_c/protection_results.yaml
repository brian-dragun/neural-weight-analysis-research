model: gpt2
phase: C
protection_methods:
- weight_redundancy
- checksums
- adversarial_training
protection_results:
  critical_weight_protection_map:
    h.10.attn.c_attn.bias[1670]:
    - weight_redundancy
    h.10.attn.c_attn.bias[176]:
    - weight_redundancy
    h.10.attn.c_attn.bias[1862]:
    - weight_redundancy
    h.10.attn.c_attn.bias[1906]:
    - weight_redundancy
    h.10.attn.c_attn.bias[347]:
    - weight_redundancy
    h.10.attn.c_attn.bias[362]:
    - weight_redundancy
    h.10.attn.c_attn.weight[1031558]:
    - weight_redundancy
    h.10.attn.c_attn.weight[1031750]:
    - weight_redundancy
    h.10.attn.c_attn.weight[1031794]:
    - weight_redundancy
    h.10.attn.c_attn.weight[1031983]:
    - weight_redundancy
    h.10.attn.c_attn.weight[1031989]:
    - weight_redundancy
    h.10.attn.c_attn.weight[148571]:
    - weight_redundancy
    h.10.attn.c_attn.weight[201579]:
    - weight_redundancy
    h.10.attn.c_attn.weight[613211]:
    - weight_redundancy
    h.10.attn.c_proj.bias[138]:
    - weight_redundancy
    h.10.attn.c_proj.bias[481]:
    - weight_redundancy
    h.10.attn.c_proj.weight[339594]:
    - weight_redundancy
    h.10.attn.c_proj.weight[535009]:
    - weight_redundancy
    h.10.attn.c_proj.weight[78474]:
    - weight_redundancy
    h.10.ln_2.bias[373]:
    - weight_redundancy
    h.10.ln_2.bias[481]:
    - weight_redundancy
    h.10.mlp.c_fc.bias[2178]:
    - weight_redundancy
    h.10.mlp.c_fc.bias[379]:
    - weight_redundancy
    h.10.mlp.c_fc.bias[900]:
    - weight_redundancy
    h.10.mlp.c_fc.weight[1209474]:
    - weight_redundancy
    h.10.mlp.c_fc.weight[196987]:
    - weight_redundancy
    h.10.mlp.c_fc.weight[198786]:
    - weight_redundancy
    h.10.mlp.c_proj.bias[138]:
    - weight_redundancy
    h.10.mlp.c_proj.weight[1377162]:
    - weight_redundancy
    h.11.attn.c_attn.bias[2049]:
    - weight_redundancy
    h.11.attn.c_attn.bias[2050]:
    - weight_redundancy
    h.11.attn.c_attn.bias[2053]:
    - weight_redundancy
    h.11.attn.c_attn.bias[2059]:
    - weight_redundancy
    h.11.attn.c_attn.bias[2061]:
    - weight_redundancy
    h.11.attn.c_attn.bias[2078]:
    - weight_redundancy
    h.11.attn.c_attn.bias[2089]:
    - weight_redundancy
    h.11.attn.c_attn.bias[2095]:
    - weight_redundancy
    h.11.attn.c_attn.bias[2249]:
    - weight_redundancy
    h.11.attn.c_attn.bias[2274]:
    - weight_redundancy
    h.11.attn.c_attn.bias[2288]:
    - weight_redundancy
    h.11.attn.c_attn.bias[2290]:
    - weight_redundancy
    h.11.attn.c_attn.bias[250]:
    - weight_redundancy
    h.11.attn.c_attn.bias[277]:
    - weight_redundancy
    h.11.attn.c_attn.bias[302]:
    - weight_redundancy
    h.11.attn.c_attn.bias[760]:
    - weight_redundancy
    h.11.attn.c_attn.weight[320005]:
    - weight_redundancy
    h.11.attn.c_attn.weight[320007]:
    - weight_redundancy
    h.11.attn.c_attn.weight[320013]:
    - weight_redundancy
    h.11.attn.c_attn.weight[320030]:
    - weight_redundancy
    h.11.attn.c_attn.weight[320032]:
    - weight_redundancy
    h.11.attn.c_attn.weight[320033]:
    - weight_redundancy
    h.11.attn.c_attn.weight[320047]:
    - weight_redundancy
    h.11.attn.c_attn.weight[320049]:
    - weight_redundancy
    h.11.attn.c_attn.weight[320201]:
    - weight_redundancy
    h.11.attn.c_attn.weight[320226]:
    - weight_redundancy
    h.11.attn.c_attn.weight[320240]:
    - weight_redundancy
    h.11.attn.c_attn.weight[320242]:
    - weight_redundancy
    h.11.attn.c_proj.bias[266]:
    - weight_redundancy
    h.11.attn.c_proj.bias[314]:
    - weight_redundancy
    h.11.attn.c_proj.bias[393]:
    - weight_redundancy
    h.11.attn.c_proj.bias[480]:
    - weight_redundancy
    h.11.attn.c_proj.bias[64]:
    - weight_redundancy
    h.11.attn.c_proj.bias[87]:
    - weight_redundancy
    h.11.attn.c_proj.weight[395967]:
    - weight_redundancy
    h.11.attn.c_proj.weight[397370]:
    - weight_redundancy
    h.11.attn.c_proj.weight[397449]:
    - weight_redundancy
    h.11.attn.c_proj.weight[397503]:
    - weight_redundancy
    h.11.attn.c_proj.weight[399039]:
    - weight_redundancy
    h.11.attn.c_proj.weight[401978]:
    - weight_redundancy
    h.11.attn.c_proj.weight[402057]:
    - weight_redundancy
    h.11.attn.c_proj.weight[403593]:
    - weight_redundancy
    h.11.attn.c_proj.weight[403647]:
    - weight_redundancy
    h.11.attn.c_proj.weight[412095]:
    - weight_redundancy
    h.11.attn.c_proj.weight[412863]:
    - weight_redundancy
    h.11.attn.c_proj.weight[415167]:
    - weight_redundancy
    h.11.attn.c_proj.weight[416649]:
    - weight_redundancy
    h.11.attn.c_proj.weight[416703]:
    - weight_redundancy
    h.11.attn.c_proj.weight[418239]:
    - weight_redundancy
    h.11.attn.c_proj.weight[419007]:
    - weight_redundancy
    h.11.attn.c_proj.weight[429759]:
    - weight_redundancy
    h.11.attn.c_proj.weight[431295]:
    - weight_redundancy
    h.11.ln_2.bias[373]:
    - weight_redundancy
    h.11.ln_2.bias[393]:
    - weight_redundancy
    h.11.ln_2.bias[447]:
    - weight_redundancy
    h.11.ln_2.bias[481]:
    - weight_redundancy
    h.11.mlp.c_fc.bias[2928]:
    - weight_redundancy
    h.11.mlp.c_fc.bias[611]:
    - weight_redundancy
    h.11.mlp.c_fc.weight[1002083]:
    - weight_redundancy
    h.11.mlp.c_fc.weight[1373795]:
    - weight_redundancy
    h.11.mlp.c_fc.weight[1478243]:
    - weight_redundancy
    h.11.mlp.c_fc.weight[1926755]:
    - weight_redundancy
    h.11.mlp.c_fc.weight[965219]:
    - weight_redundancy
    h.11.mlp.c_proj.bias[314]:
    - weight_redundancy
    h.11.mlp.c_proj.bias[36]:
    - weight_redundancy
    h.11.mlp.c_proj.bias[374]:
    - weight_redundancy
    h.11.mlp.c_proj.bias[430]:
    - weight_redundancy
    h.11.mlp.c_proj.bias[496]:
    - weight_redundancy
    h.11.mlp.c_proj.weight[2235194]:
    - weight_redundancy
    h.11.mlp.c_proj.weight[2235310]:
    - weight_redundancy
    h.11.mlp.c_proj.weight[469562]:
    - weight_redundancy
    h.2.attn.c_attn.bias[741]:
    - weight_redundancy
    h.2.ln_2.weight[138]:
    - weight_redundancy
    h.3.ln_2.bias[138]:
    - weight_redundancy
    h.3.ln_2.bias[64]:
    - weight_redundancy
    h.3.mlp.c_fc.weight[424963]:
    - weight_redundancy
    h.4.ln_2.bias[138]:
    - weight_redundancy
    h.4.ln_2.bias[480]:
    - weight_redundancy
    h.4.mlp.c_fc.bias[2883]:
    - weight_redundancy
    h.5.mlp.c_fc.bias[1505]:
    - weight_redundancy
    h.5.mlp.c_fc.bias[1888]:
    - weight_redundancy
    h.6.attn.c_attn.weight[613237]:
    - weight_redundancy
    h.6.attn.c_attn.weight[613999]:
    - weight_redundancy
    h.6.attn.c_proj.bias[138]:
    - weight_redundancy
    h.6.attn.c_proj.bias[496]:
    - weight_redundancy
    h.6.mlp.c_fc.bias[2037]:
    - weight_redundancy
    h.6.mlp.c_fc.bias[437]:
    - weight_redundancy
    h.6.mlp.c_proj.bias[138]:
    - weight_redundancy
    h.7.attn.c_attn.weight[613119]:
    - weight_redundancy
    h.7.mlp.c_fc.bias[2367]:
    - weight_redundancy
    h.7.mlp.c_fc.bias[2489]:
    - weight_redundancy
    h.7.mlp.c_proj.bias[138]:
    - weight_redundancy
    h.8.attn.c_attn.bias[1550]:
    - weight_redundancy
    h.8.attn.c_attn.bias[2140]:
    - weight_redundancy
    h.8.attn.c_attn.weight[1031438]:
    - weight_redundancy
    h.8.attn.c_attn.weight[613507]:
    - weight_redundancy
    h.8.attn.c_proj.bias[138]:
    - weight_redundancy
    h.8.attn.c_proj.weight[517002]:
    - weight_redundancy
    h.8.mlp.c_fc.bias[1253]:
    - weight_redundancy
    h.8.mlp.c_fc.bias[1640]:
    - weight_redundancy
    h.8.mlp.c_proj.bias[138]:
    - weight_redundancy
    h.9.attn.c_attn.bias[2265]:
    - weight_redundancy
    h.9.attn.c_attn.bias[475]:
    - weight_redundancy
    h.9.attn.c_attn.weight[1032153]:
    - weight_redundancy
    h.9.attn.c_proj.bias[138]:
    - weight_redundancy
    h.9.attn.c_proj.weight[82314]:
    - weight_redundancy
    h.9.mlp.c_fc.bias[1503]:
    - weight_redundancy
    h.9.mlp.c_fc.bias[1889]:
    - weight_redundancy
    h.9.mlp.c_fc.bias[840]:
    - weight_redundancy
    h.9.mlp.c_fc.weight[198111]:
    - weight_redundancy
    h.9.mlp.c_proj.bias[138]:
    - weight_redundancy
    ln_f.weight[496]:
    - weight_redundancy
  defense_effectiveness:
    weight_redundancy: 0.0
  performance_overhead: .nan
  protection_applied:
    adversarial_training:
      error: cannot convert float NaN to integer
    checksums:
      error: 'Unknown protection method: checksums'
    weight_redundancy:
      backup_count: 50
      checksum_count: 50
      method: weight_redundancy
      overhead_estimate: 0.0004
      protected_weight_list:
      - h.11.mlp.c_fc.weight[965219]
      - h.11.mlp.c_proj.bias[496]
      - h.11.mlp.c_proj.bias[430]
      - h.6.mlp.c_fc.bias[437]
      - h.10.ln_2.bias[373]
      - h.10.mlp.c_fc.bias[379]
      - h.5.mlp.c_fc.bias[1888]
      - h.8.mlp.c_fc.bias[1253]
      - h.11.attn.c_attn.bias[302]
      - h.11.mlp.c_proj.weight[469562]
      - h.10.ln_2.bias[481]
      - h.8.mlp.c_fc.bias[1640]
      - h.5.mlp.c_fc.bias[1505]
      - h.11.ln_2.bias[373]
      - h.10.attn.c_attn.weight[613211]
      - h.11.attn.c_proj.bias[393]
      - h.11.attn.c_attn.bias[2059]
      - h.10.mlp.c_fc.bias[900]
      - h.4.ln_2.bias[138]
      - h.4.ln_2.bias[480]
      - h.10.attn.c_attn.bias[347]
      - h.11.attn.c_attn.bias[2290]
      - h.11.attn.c_attn.bias[2061]
      - h.3.mlp.c_fc.weight[424963]
      - h.11.attn.c_proj.bias[314]
      - h.11.mlp.c_proj.bias[314]
      - h.11.attn.c_attn.weight[320242]
      - h.7.mlp.c_fc.bias[2367]
      - ln_f.weight[496]
      - h.9.mlp.c_fc.bias[1503]
      - h.11.attn.c_proj.weight[403647]
      - h.10.attn.c_proj.bias[138]
      - h.11.attn.c_attn.bias[2078]
      - h.11.mlp.c_fc.weight[1002083]
      - h.11.mlp.c_fc.bias[611]
      - h.11.attn.c_proj.weight[402057]
      - h.3.ln_2.bias[138]
      - h.10.mlp.c_proj.bias[138]
      - h.11.mlp.c_fc.weight[1926755]
      - h.11.attn.c_attn.bias[277]
      - h.9.attn.c_proj.bias[138]
      - h.10.attn.c_attn.bias[1862]
      - h.9.mlp.c_fc.bias[1889]
      - h.11.attn.c_proj.weight[397449]
      - h.10.attn.c_proj.weight[78474]
      - h.10.attn.c_attn.weight[1031750]
      - h.11.attn.c_attn.bias[2053]
      - h.11.ln_2.bias[447]
      - h.11.attn.c_attn.weight[320013]
      - h.11.mlp.c_proj.bias[374]
      success: true
      weights_protected: 50
  protection_coverage: 0.3546099290780142
  residual_vulnerability:
    partially_protected_weights: 0
    residual_risk_score: 0.6453900709219857
    unprotected_weights: 91
    vulnerable_layers:
    - ln_f.weight
    - h.11.attn.c_proj.weight
    - h.5.mlp.c_fc.bias
    - h.9.attn.c_proj.bias
    - h.10.ln_2.bias
    - h.11.mlp.c_fc.weight
    - h.11.mlp.c_fc.bias
    - h.6.attn.c_attn.weight
    - h.4.mlp.c_fc.bias
    - h.7.attn.c_attn.weight
    - h.6.mlp.c_fc.bias
    - h.2.ln_2.weight
    - h.10.mlp.c_fc.weight
    - h.9.mlp.c_proj.bias
    - h.10.mlp.c_proj.bias
    - h.10.attn.c_attn.weight
    - h.8.mlp.c_proj.bias
    - h.10.mlp.c_fc.bias
    - h.11.attn.c_attn.bias
    - h.10.mlp.c_proj.weight
    - h.9.attn.c_attn.weight
    - h.9.attn.c_proj.weight
    - h.9.mlp.c_fc.weight
    - h.3.mlp.c_fc.weight
    - h.10.attn.c_proj.bias
    - h.9.mlp.c_fc.bias
    - h.7.mlp.c_fc.bias
    - h.8.attn.c_proj.bias
    - h.8.attn.c_proj.weight
    - h.11.ln_2.bias
    - h.8.attn.c_attn.bias
    - h.7.mlp.c_proj.bias
    - h.11.mlp.c_proj.bias
    - h.9.attn.c_attn.bias
    - h.6.attn.c_proj.bias
    - h.2.attn.c_attn.bias
    - h.11.mlp.c_proj.weight
    - h.8.mlp.c_fc.bias
    - h.4.ln_2.bias
    - h.8.attn.c_attn.weight
    - h.11.attn.c_proj.bias
    - h.3.ln_2.bias
    - h.11.attn.c_attn.weight
    - h.10.attn.c_attn.bias
    - h.6.mlp.c_proj.bias
    - h.10.attn.c_proj.weight
test_results:
  attack_resistance:
    bit_flip:
      attack_method: bit_flip
      detection_rate: 0.95
      protection_triggered: true
      recovery_rate: 0.8
      resistance_score: 0.9
    fault_injection:
      attack_method: fault_injection
      detection_rate: 0.7
      protection_triggered: true
      recovery_rate: 0.5
      resistance_score: 0.6
    fgsm:
      attack_method: fgsm
      detection_rate: 0.9
      protection_triggered: true
      recovery_rate: 0.7
      resistance_score: 0.8
    pgd:
      attack_method: pgd
      detection_rate: 0.8
      protection_triggered: true
      recovery_rate: 0.6
      resistance_score: 0.7
  overall_security_score: !!python/object/apply:numpy._core.multiarray.scalar
  - !!python/object/apply:numpy.dtype
    args:
    - f8
    - false
    - true
    state: !!python/tuple
    - 3
    - <
    - null
    - null
    - null
    - -1
    - -1
    - 0
  - !!binary |
    cT0K16Nw6j8=
  protection_effectiveness:
    bit_flip: 0.935
    fault_injection: 0.71
    fgsm: 0.8700000000000001
    pgd: 0.79
  recovery_performance:
    bit_flip:
      attack_method: bit_flip
      data_integrity_restored: true
      recovery_attempted: true
      recovery_successful: true
      recovery_time: 0.2388295748647815
    fault_injection:
      attack_method: fault_injection
      data_integrity_restored: true
      recovery_attempted: true
      recovery_successful: true
      recovery_time: 0.7234772487633614
    fgsm:
      attack_method: fgsm
      data_integrity_restored: true
      recovery_attempted: true
      recovery_successful: true
      recovery_time: 0.12238818198801625
    pgd:
      attack_method: pgd
      data_integrity_restored: true
      recovery_attempted: true
      recovery_successful: true
      recovery_time: 0.47654939295702026
